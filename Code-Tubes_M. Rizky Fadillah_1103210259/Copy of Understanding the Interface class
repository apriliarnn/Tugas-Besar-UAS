{"cells":[{"cell_type":"markdown","metadata":{"id":"ojDvWjucmRds"},"source":["# Understanding the Interface class"]},{"cell_type":"markdown","metadata":{"id":"FCiUFwJcmRdw"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbF7VdZtmRdw"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]"]},{"cell_type":"markdown","source":["Kode ini menginstal library yang diperlukan untuk pengembangan proyek NLP, termasuk datasets untuk memuat dan mengelola dataset, evaluate untuk mengevaluasi kinerja model, dan transformers[sentencepiece] untuk bekerja dengan model-model canggih dari Hugging Face yang menggunakan SentencePiece tokenizer, sehingga memudahkan implementasi dan eksperimen dengan berbagai model bahasa alami."],"metadata":{"id":"XIALOhMPmXKr"}},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"id":"-w60txOkmTyl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Kode ini menginstal Gradio, sebuah library Python yang memungkinkan pengguna untuk dengan mudah membuat antarmuka web interaktif untuk model machine learning, termasuk model NLP, sehingga memudahkan dalam demo, eksperimen, dan berbagi model dengan orang lain secara cepat dan intuitif."],"metadata":{"id":"jXp5leT4mllG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hadt0TwfmRdx"},"outputs":[],"source":["import numpy as np\n","import gradio as gr\n","\n","\n","def reverse_audio(audio):\n","    sr, data = audio\n","    reversed_audio = (sr, np.flipud(data))\n","    return reversed_audio\n","\n","\n","mic = gr.Audio(source=\"microphone\", type=\"numpy\", label=\"Speak here...\")\n","gr.Interface(reverse_audio, mic, \"audio\").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34YDT_vbmRdy"},"outputs":[],"source":["import numpy as np\n","import gradio as gr\n","\n","notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n","\n","\n","def generate_tone(note, octave, duration):\n","    sr = 48000\n","    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n","    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n","    duration = int(duration)\n","    audio = np.linspace(0, duration, duration * sr)\n","    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n","    return (sr, audio)\n","\n","\n","gr.Interface(\n","    generate_tone,\n","    [\n","        gr.Dropdown(notes, type=\"index\"),\n","        gr.Slider(minimum=4, maximum=6, step=1),\n","        gr.Textbox(type=\"number\", value=1, label=\"Duration in seconds\"),\n","    ],\n","    \"audio\",\n",").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItBdjZXHmRdy"},"outputs":[],"source":["from transformers import pipeline\n","import gradio as gr\n","\n","model = pipeline(\"automatic-speech-recognition\")\n","\n","\n","def transcribe_audio(mic=None, file=None):\n","    if mic is not None:\n","        audio = mic\n","    elif file is not None:\n","        audio = file\n","    else:\n","        return \"You must either provide a mic recording or a file\"\n","    transcription = model(audio)[\"text\"]\n","    return transcription\n","\n","\n","gr.Interface(\n","    fn=transcribe_audio,\n","    inputs=[\n","        gr.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n","        gr.Audio(source=\"upload\", type=\"filepath\", optional=True),\n","    ],\n","    outputs=\"text\",\n",").launch()"]}],"metadata":{"colab":{"name":"Understanding the Interface class","provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/master/course/en/chapter9/section3.ipynb","timestamp":1735998995638}]}},"nbformat":4,"nbformat_minor":0}